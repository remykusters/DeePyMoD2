{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# DeepMoD stuff\n",
    "from deepymod_torch import DeepMoD\n",
    "from deepymod_torch.model.func_approx import NN\n",
    "from deepymod_torch.model.library import Library1D\n",
    "from deepymod_torch.model.constraint import LeastSquares\n",
    "from deepymod_torch.model.sparse_estimators import Threshold\n",
    "from deepymod_torch.training import train_split_full\n",
    "from deepymod_torch.training.sparsity_scheduler import TrainTestPeriodic\n",
    "\n",
    "from phimal_utilities.data import Dataset\n",
    "from phimal_utilities.data.kdv import DoubleSoliton\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device ='cuda'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "    \n",
    "# Settings for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making data\n",
    "v = 0.1\n",
    "A = 1.0\n",
    "x = np.linspace(-5, 5, 100)\n",
    "t = np.linspace(0.0, 1.0, 50)\n",
    "\n",
    "x_grid, t_grid = np.meshgrid(x, t, indexing='ij')\n",
    "dataset = Dataset(DoubleSoliton, c=[5.0, 2.0], x0=[-3.0, -1.0])\n",
    "X, y = dataset.create_dataset(x_grid.reshape(-1, 1), t_grid.reshape(-1, 1), n_samples=1000, noise=0.4, normalize=False, random=True)\n",
    "X, y = X.to(device), y.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = NN(2, [30, 30, 30, 30, 30], 1)\n",
    "library = Library1D(poly_order=2, diff_order=3) # Library function\n",
    "estimator = Threshold(0.1) #Clustering() # Sparse estimator \n",
    "constraint = LeastSquares() # How to constrain\n",
    "model = DeepMoD(network, library, estimator, constraint).to(device) # Putting it all in the model\n",
    "  \n",
    "sparsity_scheduler = TrainTestPeriodic(patience=8, periodicity=50, delta=1e-5)\n",
    "optimizer = torch.optim.Adam(model.parameters(), betas=(0.99, 0.999), amsgrad=True, lr=2e-3) # Defining optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Iteration | Progress | Time remaining |     Loss |      MSE |      Reg |    L1 norm |\n",
      "       3150     12.60%             756s   7.12e-02   7.10e-02   1.85e-04   2.73e+00 Algorithm converged. Stopping training.\n"
     ]
    }
   ],
   "source": [
    "train_split_full(model, X, y, optimizer, sparsity_scheduler, log_dir='data/1000_0.2/', write_iterations=25, max_iterations=25000, delta=1e-3, patience=8) # Runni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([False, False, False,  True, False,  True, False, False, False, False,\n",
       "         False, False], device='cuda:0')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.sparsity_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
