{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example ODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we provide a simple example of the DeepMoD algorithm by applying it on the Burgers' equation. \n",
    "\n",
    "We start by importing the required libraries and setting the plotting style:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1279e20b0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# General imports\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "# DeepMoD functions\n",
    "\n",
    "from deepymod_torch import DeepMoD\n",
    "from deepymod_torch.model.func_approx import NN\n",
    "from deepymod_torch.model.constraint import LeastSquares\n",
    "from deepymod_torch.model.sparse_estimators import Threshold,PDEFIND\n",
    "from deepymod_torch.training import train_split_full\n",
    "from deepymod_torch.training.sparsity_scheduler import TrainTestPeriodic\n",
    "from scipy.io import loadmat\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch.autograd import grad\n",
    "from itertools import combinations\n",
    "from functools import reduce\n",
    "from typing import Tuple\n",
    "from deepymod_torch.utils.types import TensorList\n",
    "from deepymod_torch import Library\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from scipy.integrate import odeint\n",
    "\n",
    "# Settings for reproducibility\n",
    "np.random.seed(40)\n",
    "torch.manual_seed(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we prepare the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dU_dt_sin(U, t):\n",
    "    # Here U is a vector such that y=U[0] and z=U[1]. This function should return [y', z']\n",
    "    return [U[1], -1*U[1] - 5*np.sin(U[0])]\n",
    "U0 = [2.5, 0.4]\n",
    "ts = np.linspace(0, 8, 500)\n",
    "Y = odeint(dU_dt_sin, U0, ts)\n",
    "T = ts.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can potentially rescale the Y and T axis and we plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_rs = T\n",
    "Y_rs = Y/np.max(np.abs(Y),axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot it to get an idea of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(T_rs, Y_rs[:,0])\n",
    "ax.plot(T_rs, Y_rs[:,1])\n",
    "ax.set_xlabel('t')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_samples = 400\n",
    "\n",
    "idx = np.random.permutation(Y.shape[0])\n",
    "X_train = torch.tensor(T_rs[idx, :][:number_of_samples], dtype=torch.float32, requires_grad=True)\n",
    "y_train = torch.tensor(Y_rs[idx, :][:number_of_samples], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([400, 1]) torch.Size([400, 2])\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup a custom library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import grad\n",
    "from itertools import combinations, product\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we show an example where we create a custom library. $\\theta$ in this case containe $[1,u,v, sin(u),cos(u)]$ to showcase that non-linear terms can easily be added to the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def library_non_linear_ODE(input, poly_order, diff_order):\n",
    "    \n",
    "    prediction, data = input\n",
    "    samples = prediction.shape[0]\n",
    "    \n",
    "    # Construct the theta matrix\n",
    "    C = torch.ones_like(prediction[:,0]).view(samples, -1)\n",
    "    u = prediction[:,0].view(samples, -1)\n",
    "    v = prediction[:,1].view(samples, -1)\n",
    "    theta = torch.cat((C, u, v, torch.cos(u), torch.sin(u)),dim=1)\n",
    "\n",
    "    # Construct a list of time_derivatives \n",
    "    time_deriv_list = []\n",
    "    for output in torch.arange(prediction.shape[1]):\n",
    "        dy = grad(prediction[:,output], data, grad_outputs=torch.ones_like(prediction[:,output]), create_graph=True)[0]\n",
    "        time_deriv = dy[:, 0:1]\n",
    "        time_deriv_list.append(time_deriv)\n",
    "        \n",
    "    return time_deriv_list, theta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== Library helper functions =======================\n",
    "def library_poly(prediction: torch.Tensor, max_order: int) -> torch.Tensor:\n",
    "    \"\"\"[summary]\n",
    "\n",
    "    Args:\n",
    "        prediction (torch.Tensor): [description]\n",
    "        max_order (int): [description]\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: [description]\n",
    "    \"\"\"\n",
    "    u = torch.ones_like(prediction)\n",
    "    for order in np.arange(1, max_order+1):\n",
    "        u = torch.cat((u, u[:, order-1:order] * prediction), dim=1)\n",
    "\n",
    "    return u\n",
    "\n",
    "\n",
    "def library_deriv(data: torch.Tensor, prediction: torch.Tensor, max_order: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"[summary]\n",
    "\n",
    "    Args:\n",
    "        data (torch.Tensor): [description]\n",
    "        prediction (torch.Tensor): [description]\n",
    "        max_order (int): [description]\n",
    "\n",
    "    Returns:\n",
    "        Tuple[torch.Tensor, torch.Tensor]: [description]\n",
    "    \"\"\"\n",
    "    dy = grad(prediction, data, grad_outputs=torch.ones_like(prediction), create_graph=True)[0]\n",
    "    time_deriv = dy[:, 0:1]\n",
    "\n",
    "    if max_order == 0:\n",
    "        du = torch.ones_like(time_deriv)\n",
    "    else:\n",
    "        du = torch.cat((torch.ones_like(time_deriv), dy[:, 1:2]), dim=1)\n",
    "        if max_order > 1:\n",
    "            for order in np.arange(1, max_order):\n",
    "                du = torch.cat((du, grad(du[:, order:order+1], data,\n",
    "                                grad_outputs=torch.ones_like(prediction), create_graph=True)[0][:, 1:2]), dim=1)\n",
    "\n",
    "    return time_deriv, du"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Library_nonlinear(Library):\n",
    "    \"\"\"[summary]\n",
    "\n",
    "    Args:\n",
    "        Library ([type]): [description]\n",
    "    \"\"\"\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "    def library(self, input: Tuple[torch.Tensor, torch.Tensor]) -> Tuple[TensorList, TensorList]:\n",
    "        \"\"\"[summary]\n",
    "\n",
    "        Args:\n",
    "            input (Tuple[torch.Tensor, torch.Tensor]): [description]\n",
    "\n",
    "        Returns:\n",
    "            Tuple[TensorList, TensorList]: [description]\n",
    "        \"\"\"\n",
    "    \n",
    "        prediction, data = input\n",
    "        samples = prediction.shape[0]\n",
    "        poly_list = []\n",
    "        deriv_list = []\n",
    "        time_deriv_list = []\n",
    "        \n",
    "        \n",
    "        # Construct the theta matrix\n",
    "        C = torch.ones_like(prediction[:,0]).view(samples, -1)\n",
    "        u = prediction[:,0].view(samples, -1)\n",
    "        v = prediction[:,1].view(samples, -1)\n",
    "        theta = torch.cat((C, u, v, torch.sin(u)),dim=1)\n",
    "    \n",
    "        # Construct a list of time_derivatives \n",
    "        time_deriv_list = []\n",
    "        for output in torch.arange(prediction.shape[1]):\n",
    "            dy = grad(prediction[:,output], data, grad_outputs=torch.ones_like(prediction[:,output]), create_graph=True)[0]\n",
    "            time_deriv = dy[:, 0:1]\n",
    "            time_deriv_list.append(time_deriv)\n",
    "        \n",
    "        return time_deriv_list, [theta,theta]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuring DeepMoD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now setup the options for DeepMoD. The setup requires the dimensions of the neural network, a library function and some args for the library function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([400, 2])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration of the function approximator: \n",
    "network = NN(1, [50, 50, 50,50], 2)\n",
    "# Configuration of the function approximator: \n",
    "library = Library_nonlinear() \n",
    "# Configuration of the sparsity estimator\n",
    "estimator = PDEFIND() \n",
    "# Configuration of the constraint function\n",
    "constraint = LeastSquares() \n",
    "# Configuration of the sparsity scheduler\n",
    "sparsity_scheduler = TrainTestPeriodic(periodicity=50, patience=10, delta=1e-5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DeepMoD(network, library, estimator, constraint)\n",
    "\n",
    "# Defining optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), betas=(0.99, 0.99), amsgrad=True, lr=2e-3) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we instantiate the model. Note that the learning rate of the coefficient vector can typically be set up to an order of magnitude higher to speed up convergence without loss in accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run DeepMoD "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now run DeepMoD using all the options we have set and the training data. We need to slightly preprocess the input data for the derivatives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Iteration | Progress | Time remaining |     Loss |      MSE |      Reg |    L1 norm |\n",
      "          0      0.00%               0s   2.73e-01   2.73e-01   7.42e-05   1.94e+07 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/remykusters/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=1.40692e-08): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/Users/remykusters/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=1.40692e-08): result may not be accurate.\n",
      "  overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      14750     14.75%            2069s   2.24e-03   1.41e-03   8.32e-04   1.47e+01 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-3bbb56ef6964>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m train_split_full(model, X_train, y_train, optimizer,sparsity_scheduler, log_dir='runs/coupled/', split=0.8, test='full', write_iterations=25, max_iterations=100000, delta=1e-4\n\u001b[0;32m----> 2\u001b[0;31m                 , patience=8) \n\u001b[0m",
      "\u001b[0;32m~/Documents/GitHub/DeePyMoD2/src/deepymod_torch/training/training.py\u001b[0m in \u001b[0;36mtrain_split_full\u001b[0;34m(model, data, target, optimizer, sparsity_scheduler, test, split, log_dir, max_iterations, write_iterations, **convergence_kwargs)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0;31m# ====================== Logging =======================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m             \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthetas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_derivs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# calculating l1 adjusted coeffs but not setting mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m             \u001b[0mestimator_coeff_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator_coeffs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m             \u001b[0ml1_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstraint_coeffs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaled\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/DeePyMoD2/src/deepymod_torch/model/deepmod.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, thetas, time_derivs)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         self.coeff_vectors = [self.fit(theta, time_deriv.squeeze())[:, None]\n\u001b[0;32m---> 84\u001b[0;31m                               for theta, time_deriv in zip(normed_thetas, normed_time_derivs)]\n\u001b[0m\u001b[1;32m     85\u001b[0m         sparsity_masks = [torch.tensor(coeff_vector != 0.0, dtype=torch.bool).squeeze().to(thetas[0].device) # move to gpu if required\n\u001b[1;32m     86\u001b[0m                           for coeff_vector in self.coeff_vectors]\n",
      "\u001b[0;32m~/Documents/GitHub/DeePyMoD2/src/deepymod_torch/model/deepmod.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         self.coeff_vectors = [self.fit(theta, time_deriv.squeeze())[:, None]\n\u001b[0;32m---> 84\u001b[0;31m                               for theta, time_deriv in zip(normed_thetas, normed_time_derivs)]\n\u001b[0m\u001b[1;32m     85\u001b[0m         sparsity_masks = [torch.tensor(coeff_vector != 0.0, dtype=torch.bool).squeeze().to(thetas[0].device) # move to gpu if required\n\u001b[1;32m     86\u001b[0m                           for coeff_vector in self.coeff_vectors]\n",
      "\u001b[0;32m~/Documents/GitHub/DeePyMoD2/src/deepymod_torch/model/sparse_estimators.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    120\u001b[0m         \"\"\"\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m         \u001b[0mcoeffs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPDEFIND\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrainSTLSQ\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcoeffs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/DeePyMoD2/src/deepymod_torch/model/sparse_estimators.py\u001b[0m in \u001b[0;36mTrainSTLSQ\u001b[0;34m(X, y, alpha, delta_threshold, max_iterations, test_size, random_state)\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0miteration\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_iterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m             \u001b[0my_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_predict\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ml0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount_nonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pysindy/optimizers/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x_, y, sample_weight, **reduce_kws)\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mreduce_kws\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mind_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1e-14\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pysindy/optimizers/stlsq.py\u001b[0m in \u001b[0;36m_reduce\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    157\u001b[0m                     )\n\u001b[1;32m    158\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m                 \u001b[0mcoef_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_regress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m                 coef_i, ind_i = self._sparse_coefficients(\n\u001b[1;32m    161\u001b[0m                     \u001b[0mn_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoef_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_split_full(model, X_train, y_train, optimizer,sparsity_scheduler, log_dir='runs/coupled/', split=0.8, test='full', write_iterations=25, max_iterations=100000, delta=1e-4\n",
    "                , patience=8) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that DeepMoD has converged, it has found the following numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([False, False,  True, False]), tensor([False,  True,  True,  True])]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.sparsity_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[0.        ],\n",
      "       [0.        ],\n",
      "       [0.99714768],\n",
      "       [0.        ]]), array([[ 0.        ],\n",
      "       [ 4.79955578],\n",
      "       [-0.47297588],\n",
      "       [-5.81744003]])]\n"
     ]
    }
   ],
   "source": [
    "print(model.estimator_coeffs())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
